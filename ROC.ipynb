{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[real_pred function does below things]:\n",
    "It returns a 2D array that combined the real info of the data set (for each sample, if it really has cancer or not) and the prediction info of the data set (for each sample, if it is predicted to have cancer or not, based on CT-scan)\n",
    "To make a 3D array with multiple models for ROC function input, use the for-loop below.\n",
    "\n",
    "\n",
    "\n",
    "[ROC function does below things]:\n",
    "1. Calculates [fpr, tpr, thresholds, auc] and matches the list to its key value (trial set #) in the dictionary named PRI (meaning 'Positive Rate Information').\n",
    "2. Shows the ROC plot of each trial sets.\n",
    "\n",
    "The input data should be in a 3-D numpy ndarray :\n",
    "(# of trials sets, # of training set, 2)\n",
    "eg) data.shape = (5, 300, 2) would mean 5 different trial sets, 300 is for the number of training sets in each trial, and 2 is for y value, and predicted value in the right order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def real_pred(X_test, Y_test, model):\n",
    "    predictions = model.predict(X_test) # Predict the possibility for each sample\n",
    "    rounded = [round(x[0]) for x in predictions] # Round predictions so that it's either 0 or 1\n",
    "    real_pred_data = [Y_test, rounded] # Combine the real info data and the prediction info data into one 2D array\n",
    "    return real_pred_data\n",
    "\n",
    "#################################################################################################################### \n",
    "#You can change this function to have two parameters instead: real_pred(Y_test, pred) if you already know pred values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compare_models = []\n",
    "\n",
    "# Assume that you have different models to compare, and each model is in the list called the_models\n",
    "# If you already know the prediction values of each model, then you can instead use for loop below:\n",
    "# for i in range(the_number_of_models):\n",
    "#     compare_models += [real_pred(X_test, real_pred(Y_test, Predicted(i,:)))]\n",
    "# given that Predicted is a 2D array containing the prediction value of each model.\n",
    "\n",
    "for i in the_models:\n",
    "    compare_models += [real_pred(X_test, Y_pred, i)] # compare_model is a 3D array, suitable input for ROC function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = ['cyan', 'indigo', 'seagreen', 'yellow', 'blue', 'darkorange']\n",
    "# The number of Colors may vary depending on the number of trials sets\n",
    "# eg. if we have 5 models to check the proficiency, have 5 different colors in the list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PRI = {} # Postive Rate Information, keys = Trial set, values = list of fpr, tpr, thresholds, and roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ROC(my_data):\n",
    "    nb = my_data.shape[0] # nb indicates the number of trial sets in my_data \n",
    "    i = 1\n",
    "    for k, c in zip(range(nb), colors):\n",
    "    # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(my_data[k,0,:], my_data[k,1,:])    # [k,0,:] = real, [k,1,:] = pred\n",
    "        roc_auc = auc(fpr, tpr)  # calculates the area under roc curve\n",
    "        PRI[k] = [fpr, tpr, thresholds, roc_auc]\n",
    "        plt.plot(fpr, tpr, lw=2, color=c,label='ROC fold %d (area = %0.2f)' %(i, roc_auc)) \n",
    "        # the lable indicates the matching trial set & its area under ROC curve to the 2decimal points\n",
    "        i += 1\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k',label='Luck')\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROC(compare_models) # Run the function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
